{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0a35c7-18c2-4198-bcfd-f9b6631da7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9583e528-8aed-459f-a492-ec3d9c3a8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"data/story.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d54f7c2-8ff5-40aa-a9b3-78afc712ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file at file_path and return a string\n",
    "def load_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "            return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22146b66-789b-4c2d-95f5-75623a3b3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_file(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d5b164-7c6e-4904-b01d-623a9a46a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"o200k_harmony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0710e1-fa11-4e48-8308-483e895c318c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Encountered text corresponding to disallowed special token '<|startoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|startoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|startoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokens = \u001b[43mencoding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aiml/.venv/lib/python3.12/site-packages/tiktoken/core.py:121\u001b[39m, in \u001b[36mEncoding.encode\u001b[39m\u001b[34m(self, text, allowed_special, disallowed_special)\u001b[39m\n\u001b[32m    119\u001b[39m         disallowed_special = \u001b[38;5;28mfrozenset\u001b[39m(disallowed_special)\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m match := _special_token_regex(disallowed_special).search(text):\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[43mraise_disallowed_special_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._core_bpe.encode(text, allowed_special)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aiml/.venv/lib/python3.12/site-packages/tiktoken/core.py:432\u001b[39m, in \u001b[36mraise_disallowed_special_token\u001b[39m\u001b[34m(token)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraise_disallowed_special_token\u001b[39m(token: \u001b[38;5;28mstr\u001b[39m) -> NoReturn:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    433\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEncountered text corresponding to disallowed special token \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    434\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf you want this text to be encoded as a special token, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpass it to `allowed_special`, e.g. `allowed_special=\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m, ...\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIf you want this text to be encoded as normal text, disable the check for this token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mby passing `disallowed_special=(enc.special_tokens_set - \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    438\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTo disable this check for all special tokens, pass `disallowed_special=()`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    439\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Encountered text corresponding to disallowed special token '<|startoftext|>'.\nIf you want this text to be encoded as a special token, pass it to `allowed_special`, e.g. `allowed_special={'<|startoftext|>', ...}`.\nIf you want this text to be encoded as normal text, disable the check for this token by passing `disallowed_special=(enc.special_tokens_set - {'<|startoftext|>'})`.\nTo disable this check for all special tokens, pass `disallowed_special=()`.\n"
     ]
    }
   ],
   "source": [
    "tokens = encoding.encode(text, allowed_special=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8875bcb6-a160-4d49-a34e-fe21171a02b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e5f47d8-6626-48bf-9788-5c26051c1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the special token string for a given token id if it is a special token\n",
    "# in the embedding model's encoding; otherwise return None.\n",
    "#\n",
    "# Usage:\n",
    "#   name = special_token_name(token_id, enc=encoding)\n",
    "#   # or rely on the global `encoding` if set earlier in the notebook\n",
    "#   name = special_token_name(token_id)\n",
    "import tiktoken\n",
    "\n",
    "def special_token_name(token_id: int, enc=None):\n",
    "    \"\"\"\n",
    "    Check whether `token_id` is a special token in the embedding model's encoding\n",
    "    and return the string name of it if it is; otherwise return None.\n",
    "\n",
    "    If `enc` is not provided, this will use a global `encoding` if present,\n",
    "    otherwise it will default to tiktoken.get_encoding(\"o200k_harmony\").\n",
    "    \"\"\"\n",
    "    # Resolve the encoding to use\n",
    "    if enc is None:\n",
    "        enc = globals().get(\"encoding\") or tiktoken.get_encoding(\"o200k_harmony\")\n",
    "\n",
    "    # Build the mapping using only public API\n",
    "    # Iterate known special token strings and map their ids\n",
    "    for s in getattr(enc, \"special_tokens_set\", set()):\n",
    "        ids = enc.encode(s, allowed_special=\"all\")\n",
    "        if len(ids) == 1 and ids[0] == token_id:\n",
    "            return s\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5229de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map and filter special tokens present in `tokens`\n",
    "# Produces a dict {token_id: special_name} for unique specials encountered\n",
    "special_tokens_found = {}\n",
    "for tid in tokens:\n",
    "    name = special_token_name(tid, enc=encoding)\n",
    "    if name is not None and tid not in special_tokens_found:\n",
    "        special_tokens_found[tid] = name\n",
    "\n",
    "special_tokens_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d2d6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all special tokens in the model (excluding names containing \"reserved\")\n",
    "import tiktoken\n",
    "\n",
    "def print_special_tokens(enc=None):\n",
    "    \"\"\"\n",
    "    Print all special tokens known by the encoding, excluding any whose\n",
    "    names contain \"reserved\" (case-insensitive). Returns a sorted list of\n",
    "    (token_id, token_string) for convenience.\n",
    "    \"\"\"\n",
    "    # Resolve encoding\n",
    "    if enc is None:\n",
    "        enc = globals().get(\"encoding\") or tiktoken.get_encoding(\"o200k_harmony\")\n",
    "\n",
    "    specials = []\n",
    "    for s in getattr(enc, \"special_tokens_set\", set()):\n",
    "        if \"reserved\" in s.lower():\n",
    "            continue\n",
    "        ids = enc.encode(s, allowed_special=\"all\")\n",
    "        if len(ids) == 1:\n",
    "            specials.append((ids[0], s))\n",
    "\n",
    "    specials.sort(key=lambda x: x[0])\n",
    "    for tid, name in specials:\n",
    "        print(f\"{tid}\\t{name}\")\n",
    "    return specials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b2f69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199998\t<|startoftext|>\n",
      "199999\t<|endoftext|>\n",
      "200002\t<|return|>\n",
      "200003\t<|constrain|>\n",
      "200005\t<|channel|>\n",
      "200006\t<|start|>\n",
      "200007\t<|end|>\n",
      "200008\t<|message|>\n",
      "200012\t<|call|>\n",
      "200018\t<|endofprompt|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(199998, '<|startoftext|>'),\n",
       " (199999, '<|endoftext|>'),\n",
       " (200002, '<|return|>'),\n",
       " (200003, '<|constrain|>'),\n",
       " (200005, '<|channel|>'),\n",
       " (200006, '<|start|>'),\n",
       " (200007, '<|end|>'),\n",
       " (200008, '<|message|>'),\n",
       " (200012, '<|call|>'),\n",
       " (200018, '<|endofprompt|>')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print_special_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29348a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
